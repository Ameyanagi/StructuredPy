# Time Series Analysis with Functions

## Introduction

In this chapter, we'll analyze time series data from sensors using Python functions. We'll build a simple series of functions that can:

- Load and validate sensor data
- Calculate basic statistics
- Find patterns in the data
- Create meaningful visualizations

## Project Overview

We'll work with temperature sensor data that looks like this:

```{csv}
timestamp,temperature,humidity
2024-01-01 00:00:00,22.5,45
2024-01-01 00:01:00,22.6,46
2024-01-01 00:02:00,22.4,45
```

This data represents temperature and humidity readings taken every minute. Our goal is to create functions that help us understand this data.

## Strategy

The first thing that we have to do is to determine what we want to achieve with our analysis. In this case, we want to do something like this:


1. Data Loading and Validation
   - Load CSV files containing sensor data
   - Validate timestamp formats
   - Check for missing values
   - Verify data ranges

2. Basic Statistics
   - Calculate daily min/max/mean
   - Identify outliers
   - Compute moving averages

3. Pattern Detection
   - Find daily cycles
   - Detect anomalies
   - Calculate correlations between temperature and humidity

4. Visualization 
   - Plot time series trends
   - Create daily pattern heatmaps
   - Generate statistical summaries

The main idea is to create functions that can be used to perform these tasks in a modular way. This will make our code more readable, reusable, and easier to maintain.

## Creating that Function Stubs

### Data Management Functions

Lets start by creating the functions to load and validate our data.
We will not implement the functions yet, just define there signature and purpose.
This is called "function stubs".
This will help us to define the structure of our code. So that we can implement the functions later.


```python
def load_sensor_data(filepath):
    """
    Load sensor data from a CSV file.
    
    Example:
        data = load_sensor_data('sensor_data.csv')
    """
    pass
```

:::{.callout-tip}
The `pass` statement is a placeholder that does nothing. It's used as a temporary placeholder when a statement is required syntactically but you don't want to execute any code.
:::

:::{.callout-tip}
Here, we will be using the `pandas` library to load and manipulate our data.
If you are not familiar with `pandas`, you can learn more about it in the [official documentation](https://pandas.pydata.org/docs/).
:::

We will also create a function to check the quality of our data:

  - Validate timestamp formats
  - Check for missing values
  - Verify data ranges

```python

def validate_timestamp_format(data):
    """
    Check if timestamp column has valid date formats.
    
    Example:
        is_valid = validate_timestamp_format(data)
    """
    pass

def check_missing_values(data):
    """
    Check if data contains missing values.
    
    Example:
        has_missing = check_missing_values(data)
    """
    pass

def check_data_ranges(data):
    """
    Check if data values are within expected ranges.

    Example:
        is_valid = check_data_ranges(data)
    """
    pass
```

:::{.callout-note}
Here, we are using splitting the validation into multiple functions to make it easier to understand.
For real application, you can combine these functions in to a single function if you prefer.
:::

The good point of the functions stubs is that we can create a downstream function that uses these functions.
For example, we can create a function that checks the quality of our data by combining these functions:

```python
def check_data_quality(data):
    """
    Check if data has required columns and valid values.
    
    Example:
        is_valid = check_data_quality(data)
    """

    if not validate_timestamp_format(data):
        raise ValueError("Invalid timestamp format")

    if check_missing_values(data):
        raise ValueError("Data contains missing values")

    if not check_data_ranges(data):
        raise ValueError("Data values are out of range")

    return True
```


### Analysis Functions

Now, let's create function stubs to analyze our data:

```python
def calculate_daily_stats(data):
    """
    Calculate basic statistics for temperature and humidity.
    
    Example:
        stats = calculate_daily_stats(data)
        print(f"Average temperature: {stats['temp_mean']:.1f}°C")
    """
    pass

def detect_patterns(data):
    """
    Find recurring patterns in the data.

    Example:
        patterns = detect_patterns(data)
    """
    pass

def find_anomalies(data):
    """
    Identify unusual readings in the data.

    Example:
        anomalies = find_anomalies(data)
    """
    pass
```

### Visualization Functions

Adding functions to visualize our data:

```python
def plot_timeseries(data):
    """
    Create a line plot of temperature over time.
    
    Example:
        plot_timeseries(data)
        plt.show()
    """
    pass

def plot_daily_patterns(data):
    """
    Show daily patterns in temperature and humidity.

    Example:
        plot_daily_patterns(data)
        plt.show()
    """
    pass

def plot_statistics(data):
    """
    Create statistical summary plots.

    Example:
        plot_statistics(data)
        plt.show()
    """
    pass

```
## Writing the Tests

:::{.callout-note}
You can skip this section if you are not familiar with testing.
You can come back to this section later when you are ready to learn about testing.
:::

Now that we have defined the functions, we can write tests to check if they work as expected.
This is called "unit testing". The test will help us to check if the functions are working as expected.
The workflow of writing the test and the function is called "Test Driven Development" (TDD).

Here is an example of how to write tests for the `load_sensor_data` function:

```csv
timestamp,temperature,humidity
2024-01-01 00:00:00,22.5,45
2024-01-01 00:01:00,22.6,46
2024-01-01 00:02:00,22.4,45
```

```csv 
timestamp,temperature,humidity
2024-01-01 00:00:00,22.5,45
2024-01-01 00:01:00,22.6,46
2024-01-01 00:02:00,22.4,
```

```python
def test_load_sensor_data():
    # Test loading a valid file
    data = load_sensor_data('sensor_data.csv')
    assert data is not None, "Failed to load valid file"
    
    # Test loading a non-existent file
    data = load_sensor_data('non_existent.csv')
    assert data is None, "Loaded non-existent file"

    # Test loading a file with missing values
    data = load_sensor_data('sensor_data_missing.csv')
    assert data is None, "Loaded file with missing values"

    # Test loading a file with invalid timestamp
    data = load_sensor_data('sensor_data_invalid.csv')
    assert data is None, "Loaded file with invalid timestamp"
```

## Starting with Basic Functions

Let's begin by creating functions to load and check our data:

```python
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

def load_sensor_data(filepath):
    """
    Load sensor data from a CSV file.
    
    Example:
        data = load_sensor_data('sensor_data.csv')
    """
    try:
        # Read CSV file with pandas
        data = pd.read_csv(filepath)
        
        # Convert timestamp string to datetime
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        
        return data
    except FileNotFoundError:
        print(f"Error: File {filepath} not found")
        return None
    except Exception as e:
        print(f"Error loading data: {e}")
        return None

def check_data_quality(data):
    """
    Check if data has required columns and valid values.
    
    Example:
        is_valid = check_data_quality(data)
    """
    # Check required columns
    required_columns = ['timestamp', 'temperature', 'humidity']
    has_columns = all(col in data.columns for col in required_columns)
    
    if not has_columns:
        print("Error: Missing required columns")
        return False
    
    # Check for missing values
    if data.isnull().any().any():
        print("Warning: Data contains missing values")
        
    return True
```

## Analysis Functions

Now let's create functions to analyze our data:

```python
def calculate_basic_stats(data):
    """
    Calculate basic statistics for temperature and humidity.
    
    Example:
        stats = calculate_basic_stats(data)
        print(f"Average temperature: {stats['temp_mean']:.1f}°C")
    """
    stats = {
        'temp_mean': data['temperature'].mean(),
        'temp_max': data['temperature'].max(),
        'temp_min': data['temperature'].min(),
        'humid_mean': data['humidity'].mean(),
        'readings_count': len(data)
    }
    return stats

def find_outliers(data, std_threshold=3):
    """
    Find outlier readings based on standard deviation.
    
    Example:
        outliers = find_outliers(data, std_threshold=2)
    """
    temp_mean = data['temperature'].mean()
    temp_std = data['temperature'].std()
    
    outliers = data[
        abs(data['temperature'] - temp_mean) > std_threshold * temp_std
    ]
    
    return outliers
```

## Visualization Functions

Adding functions to visualize our data:

```python
def plot_temperature_trend(data):
    """
    Create a line plot of temperature over time.
    
    Example:
        plot_temperature_trend(data)
        plt.show()
    """
    plt.figure(figsize=(12, 6))
    plt.plot(data['timestamp'], data['temperature'])
    plt.title('Temperature Over Time')
    plt.xlabel('Time')
    plt.ylabel('Temperature (°C)')
    plt.grid(True)
    
def plot_daily_pattern(data):
    """
    Show average temperature pattern by hour of day.
    
    Example:
        plot_daily_pattern(data)
        plt.show()
    """
    # Extract hour from timestamp
    data['hour'] = data['timestamp'].dt.hour
    
    # Calculate mean temperature for each hour
    daily_pattern = data.groupby('hour')['temperature'].mean()
    
    plt.figure(figsize=(10, 6))
    daily_pattern.plot(kind='bar')
    plt.title('Average Temperature by Hour')
    plt.xlabel('Hour of Day')
    plt.ylabel('Average Temperature (°C)')
```

## Putting It All Together

Let's create a function that uses all our analysis tools:

```python
def analyze_sensor_data(filepath):
    """
    Perform complete analysis of sensor data.
    
    Example:
        results = analyze_sensor_data('sensor_data.csv')
    """
    # Load data
    data = load_sensor_data(filepath)
    if data is None:
        return None
    
    # Check data quality
    if not check_data_quality(data):
        return None
    
    # Perform analysis
    results = {
        'statistics': calculate_basic_stats(data),
        'outliers': find_outliers(data),
    }
    
    # Create visualizations
    plot_temperature_trend(data)
    plt.savefig('temperature_trend.png')
    plt.close()
    
    plot_daily_pattern(data)
    plt.savefig('daily_pattern.png')
    plt.close()
    
    return results
```

## Using Our Functions

Here's how to use the functions we created:

```python
# Load and analyze data
filepath = "sensor_data.csv"
results = analyze_sensor_data(filepath)

if results:
    # Print statistics
    stats = results['statistics']
    print(f"Data Summary:")
    print(f"- Average temperature: {stats['temp_mean']:.1f}°C")
    print(f"- Temperature range: {stats['temp_min']:.1f}°C to {stats['temp_max']:.1f}°C")
    print(f"- Number of readings: {stats['readings_count']}")
    
    # Report outliers
    outliers = results['outliers']
    print(f"\nFound {len(outliers)} outlier readings")
```

## Benefits of Functional Approach

Our functional approach has several advantages:

1. Each function has a single, clear purpose
2. Functions can be tested independently
3. Easy to add new analysis features
4. Code is reusable across different projects

## Practice Exercises

1. **Basic**: Create a function to calculate the temperature change rate between readings.
2. **Intermediate**: Add a function to detect sudden temperature spikes.
3. **Advanced**: Create a function to identify daily temperature patterns.

## What's Next

In the next chapter, we'll see how to organize this same functionality using classes, which will help us manage more complex analysis requirements.

## References

For more information on time series analysis with Python, see @time_series_python.
